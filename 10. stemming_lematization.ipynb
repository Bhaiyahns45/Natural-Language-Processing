{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "adjustable | adjust\n",
      "rafting | raft\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat 9837207709914848172\n",
      "eats  |  eat 9837207709914848172\n",
      "eat  |  eat 9837207709914848172\n",
      "ate  |  eat 9837207709914848172\n",
      "adjustable  |  adjustable 6033511944150694480\n",
      "rafting  |  raft 7154368781129989833\n",
      "ability  |  ability 11565809527369121409\n",
      "meeting  |  meeting 14798207169164081740\n",
      "better  |  well 4525988469032889948\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\n",
    "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_,  token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Customizing lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  bro 3493238095688267532\n",
      ",  |  , 2593208677638477497\n",
      "you  |  you 7624161793554793053\n",
      "wanna  |  wanna 13000462173222681081\n",
      "go  |  go 8004577259940138793\n",
      "?  |  ? 8205403955989537350\n",
      "Brah  |  Brah 5645766505577852541\n",
      ",  |  , 2593208677638477497\n",
      "do  |  do 2158845516055552166\n",
      "n't  |  not 447765159362469301\n",
      "say  |  say 8685289367999165211\n",
      "no  |  no 13055779130471031426\n",
      "!  |  ! 17494803046312582752\n",
      "I  |  I 4690420944186131903\n",
      "am  |  be 10382539506755952630\n",
      "exhausted  |  exhaust 5738807065439247694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_,  token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"}) # adding custom rule\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.text, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise1:\n",
    "\n",
    "# Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "# Write a short note on the words that have different base words using stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stemming in nltk\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | like\n",
      "children | children\n",
      "whom | whom\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "for word in lst_words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lemmatization in spacy\n",
    "\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run  |  12767647472892411841\n",
      "painting  |  paint  |  16929211676819693673\n",
      "walking  |  walk  |  1674876016505392235\n",
      "dressing  |  dress  |  12815368344456308931\n",
      "likely  |  likely  |  6740298879949941214\n",
      "children  |  child  |  737253710922290542\n",
      "who  |  who  |  3876862883474502309\n",
      "good  |  good  |  5711639017775284443\n",
      "ate  |  eat  |  9837207709914848172\n",
      "fishing  |  fishing  |  10959402079719336560\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_,\" | \",  token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | running\n",
      "painting | painting\n",
      "walking | walking\n",
      "dressing | dressing\n",
      "likely | likely\n",
      "children | child\n",
      "whom | whom\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fishing\n"
     ]
    }
   ],
   "source": [
    "for word in lst_words:\n",
    "    print(word, \"|\", lemma.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise2:\n",
    "\n",
    "# convert the given text into it's base form using both stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stemming in nltk\n",
    "\n",
    "\n",
    "#step1: Word tokenizing (spacy)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m doc:\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(word, stemmer\u001b[39m.\u001b[39;49mstem(word))\n",
      "File \u001b[1;32md:\\Natural-Language-Processing\\nlp_env\\Lib\\site-packages\\nltk\\stem\\porter.py:658\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[1;34m(self, word, to_lowercase)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstem\u001b[39m(\u001b[39mself\u001b[39m, word, to_lowercase\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    655\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[39m    :param to_lowercase: if `to_lowercase=True` the word always lowercase\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     stem \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39;49mlower() \u001b[39mif\u001b[39;00m to_lowercase \u001b[39melse\u001b[39;00m word\n\u001b[0;32m    660\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNLTK_EXTENSIONS \u001b[39mand\u001b[39;00m word \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool:\n\u001b[0;32m    661\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool[stem]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "for word in doc:\n",
    "    print(word, stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha | latha\n",
      "is | is\n",
      "very | veri\n",
      "multi | multi\n",
      "talented | talent\n",
      "girl | girl\n",
      ". | .\n",
      "She | she\n",
      "is | is\n",
      "good | good\n",
      "at | at\n",
      "many | mani\n",
      "skills | skill\n",
      "like | like\n",
      "dancing | danc\n",
      ", | ,\n",
      "running | run\n",
      ", | ,\n",
      "singing | sing\n",
      ", | ,\n",
      "playing | play\n",
      ". | .\n",
      "She | she\n",
      "also | also\n",
      "likes | like\n",
      "eating | eat\n",
      "Pav | pav\n",
      "Bhagi | bhagi\n",
      ". | .\n",
      "she | she\n",
      "has | ha\n",
      "a | a\n",
      "habit | habit\n",
      "of | of\n",
      "fishing | fish\n",
      "and | and\n",
      "swimming | swim\n",
      "too | too\n",
      ". | .\n",
      "Besides | besid\n",
      "all | all\n",
      "this | thi\n",
      ", | ,\n",
      "she | she\n",
      "is | is\n",
      "a | a\n",
      "wonderful | wonder\n",
      "at | at\n",
      "cooking | cook\n",
      "too | too\n",
      ". | .\n",
      "\n",
      " | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "using_spacy = []\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", stemmer.stem(str(word)))\n",
    "    using_spacy.append(stemmer.stem(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latha',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'multi',\n",
       " 'talent',\n",
       " 'girl',\n",
       " '.',\n",
       " 'she',\n",
       " 'is',\n",
       " 'good',\n",
       " 'at',\n",
       " 'mani',\n",
       " 'skill',\n",
       " 'like',\n",
       " 'danc',\n",
       " ',',\n",
       " 'run',\n",
       " ',',\n",
       " 'sing',\n",
       " ',',\n",
       " 'play',\n",
       " '.',\n",
       " 'she',\n",
       " 'also',\n",
       " 'like',\n",
       " 'eat',\n",
       " 'pav',\n",
       " 'bhagi',\n",
       " '.',\n",
       " 'she',\n",
       " 'ha',\n",
       " 'a',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'fish',\n",
       " 'and',\n",
       " 'swim',\n",
       " 'too',\n",
       " '.',\n",
       " 'besid',\n",
       " 'all',\n",
       " 'thi',\n",
       " ',',\n",
       " 'she',\n",
       " 'is',\n",
       " 'a',\n",
       " 'wonder',\n",
       " 'at',\n",
       " 'cook',\n",
       " 'too',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latha is veri multi talent girl . she is good at mani skill like danc , run , sing , play . she also like eat pav bhagi . she ha a habit of fish and swim too . besid all thi , she is a wonder at cook too . \\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(using_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1: Word tokenizing (nltk)\n",
    "\n",
    "doc2 = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha | latha\n",
      "is | is\n",
      "very | veri\n",
      "multi | multi\n",
      "talented | talent\n",
      "girl.She | girl.sh\n",
      "is | is\n",
      "good | good\n",
      "at | at\n",
      "many | mani\n",
      "skills | skill\n",
      "like | like\n",
      "dancing | danc\n",
      ", | ,\n",
      "running | run\n",
      ", | ,\n",
      "singing | sing\n",
      ", | ,\n",
      "playing.She | playing.sh\n",
      "also | also\n",
      "likes | like\n",
      "eating | eat\n",
      "Pav | pav\n",
      "Bhagi | bhagi\n",
      ". | .\n",
      "she | she\n",
      "has | ha\n",
      "a | a\n",
      "habit | habit\n",
      "of | of\n",
      "fishing | fish\n",
      "and | and\n",
      "swimming | swim\n",
      "too.Besides | too.besid\n",
      "all | all\n",
      "this | thi\n",
      ", | ,\n",
      "she | she\n",
      "is | is\n",
      "a | a\n",
      "wonderful | wonder\n",
      "at | at\n",
      "cooking | cook\n",
      "too | too\n",
      ". | .\n"
     ]
    }
   ],
   "source": [
    "using_nltk = []\n",
    "\n",
    "for word in doc2:\n",
    "    print(word, \"|\", stemmer.stem(word))\n",
    "    using_nltk.append(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(using_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha  |  proper noun  |  Latha\n",
      "is  |  auxiliary  |  be\n",
      "very  |  adverb  |  very\n",
      "multi  |  adjective  |  multi\n",
      "talented  |  adjective  |  talented\n",
      "girl  |  noun  |  girl\n",
      ".  |  punctuation  |  .\n",
      "She  |  pronoun  |  she\n",
      "is  |  auxiliary  |  be\n",
      "good  |  adjective  |  good\n",
      "at  |  adposition  |  at\n",
      "many  |  adjective  |  many\n",
      "skills  |  noun  |  skill\n",
      "like  |  adposition  |  like\n",
      "dancing  |  noun  |  dancing\n",
      ",  |  punctuation  |  ,\n",
      "running  |  noun  |  running\n",
      ",  |  punctuation  |  ,\n",
      "singing  |  noun  |  singing\n",
      ",  |  punctuation  |  ,\n",
      "playing  |  verb  |  play\n",
      ".  |  punctuation  |  .\n",
      "She  |  pronoun  |  she\n",
      "also  |  adverb  |  also\n",
      "likes  |  verb  |  like\n",
      "eating  |  verb  |  eat\n",
      "Pav  |  proper noun  |  Pav\n",
      "Bhagi  |  proper noun  |  Bhagi\n",
      ".  |  punctuation  |  .\n",
      "she  |  pronoun  |  she\n",
      "has  |  verb  |  have\n",
      "a  |  determiner  |  a\n",
      "habit  |  noun  |  habit\n",
      "of  |  adposition  |  of\n",
      "fishing  |  noun  |  fishing\n",
      "and  |  coordinating conjunction  |  and\n",
      "swimming  |  verb  |  swim\n",
      "too  |  adverb  |  too\n",
      ".  |  punctuation  |  .\n",
      "Besides  |  subordinating conjunction  |  besides\n",
      "all  |  determiner  |  all\n",
      "this  |  pronoun  |  this\n",
      ",  |  punctuation  |  ,\n",
      "she  |  pronoun  |  she\n",
      "is  |  auxiliary  |  be\n",
      "a  |  determiner  |  a\n",
      "wonderful  |  adjective  |  wonderful\n",
      "at  |  adposition  |  at\n",
      "cooking  |  verb  |  cook\n",
      "too  |  adverb  |  too\n",
      ".  |  punctuation  |  .\n",
      "\n",
      "  |  space  |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using lemmatisation in spacy\n",
    "\n",
    "\n",
    "#step2: getting the base form for each token using spacy 'lemma_'\n",
    "\n",
    "spacy_lemma = []\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_)\n",
    "    spacy_lemma.append(token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a habit of fishing and swim too . besides all this , she be a wonderful at cook too . \\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "\n",
    "\" \".join(spacy_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
